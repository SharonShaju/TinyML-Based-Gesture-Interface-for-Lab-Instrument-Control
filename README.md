# TinyML-Based-Gesture-Interface-for-Lab-Instrument-Control
This project presents a touch free control system that uses hand gestures to operate laboratory equipment, removing the possibility of electrostatic discharge risks in electronics lab and hygiene related issues in hospital or medical settings. After capturing image frames, an ESP32-S3 AI Camera (DFR1154 Module) uses a locally deployed Edge Impulse TinyML model to identify one of the six preset gestures. An ESP32 Wroom 32 module receives each detected gesture and its confidence value wirelessly via ESP-NOW protocol and uses a structured three-level control hierarchy to interpret the command. This system demonstrates how embedded machine learning enables a small, low-power, standalone gesture interface by carrying out gesture recognition directly on embedded hardware, eliminating the need for a conventional computer driven setup which is resource intensive.

The system controls two demonstration instruments: a function generator and a rotary knob driven by a DC motor. The selection of the instrument is the first step in the interaction flow. Next, the function generator's parameters (frequency or duty cycle) are chosen and the value is then adjusted using an increase or decrease gesture. If rotary knob is the selected instrument, the system skips the parameter selection stage and moves directly to value adjustment using the same increase or decrease gesture. This drives the motor clockwise or counter-clockwise for a short, fixed duration simulating the turning of a physical rotary knob. An SSD1306 OLED display offers clear, step-by-step visual prompts, while an active buzzer indicates success with two high frequency beeps and errors with three lower frequency beeps. Reliability is ensured by a strict 85% confidence threshold, which rejects invalid or low confidence gestures with the proper audio visual alerts.

A custom dataset of 1,368 gesture frames were collected using the same AI Camera module and sorted through a Python capture script before being uploaded to Edge Impulse for training. The finished system demonstrates that TinyML can be effectively implemented on hardware with limited resources to allow hands free intuitive control of lab equipment with real time audio and visual feedback.
